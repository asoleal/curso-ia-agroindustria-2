\documentclass[11pt, a4paper]{article}

% --- MOTOR DE FUENTES (XeLaTeX) ---
\usepackage{fontspec}
\setmainfont{DejaVu Sans}[
    BoldFont={DejaVu Sans Bold},
    ItalicFont={DejaVu Sans Oblique},
    Scale=0.9
]
\setmonofont{DejaVu Sans Mono}[Scale=0.8]

% --- IDIOMA ---
\usepackage{polyglossia}
\setmainlanguage{spanish}

% --- PAQUETES ---
\usepackage{geometry}
\usepackage{xcolor}
\usepackage{listings}
\usepackage[most]{tcolorbox}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{tikz}
\usepackage{colortbl}
\usepackage{caption}
\usepackage{subcaption}
\usetikzlibrary{shapes, arrows, positioning, babel, matrix, backgrounds, shadows}

% --- GEOMETR√çA ---
\geometry{top=2.5cm, bottom=2.5cm, left=2.5cm, right=2.5cm}
\setlength{\headheight}{28pt}
\setlength{\parskip}{0.5em}

% --- COLORES ---
\definecolor{primary}{RGB}{0, 85, 164}        % Azul Ingenier√≠a
\definecolor{accent}{RGB}{34, 139, 34}        % Verde Agro
\definecolor{danger}{RGB}{204, 0, 0}          % Rojo Alerta
\definecolor{pandas}{RGB}{19, 7, 84}          % Azul oscuro (Pandas)
\definecolor{codebg}{RGB}{245, 247, 250}
\definecolor{warning}{RGB}{255, 165, 0}       % Naranja
\definecolor{industry}{RGB}{70, 130, 180}     % Azul industrial

% --- CAJAS PERSONALIZADAS ---
\newtcolorbox{conceptbox}[1]{
    colback=blue!5!white,
    colframe=primary,
    title=#1,
    fonttitle=\bfseries,
    boxrule=0.8mm,
    arc=2mm,
    shadow={2mm}{-2mm}{0mm}{black!20}
}

\newtcolorbox{agrobox}[1]{
    colback=green!5!white,
    colframe=accent,
    title=\textbf{üå±} #1,
    fonttitle=\bfseries,
    boxrule=0.8mm,
    arc=2mm
}

\newtcolorbox{warningbox}[1]{
    colback=red!5!white,
    colframe=danger,
    title=\textbf{‚ö†} #1,
    fonttitle=\bfseries,
    boxrule=0.8mm,
    arc=2mm
}

\newtcolorbox{ethicsbox}[1]{
    colback=yellow!5!white,
    colframe=orange!75!black,
    title=\textbf{‚öñ} #1,
    fonttitle=\bfseries,
    boxrule=0.8mm,
    arc=2mm
}

\newtcolorbox{industrybox}[1]{
    colback=cyan!5!white,
    colframe=industry,
    title=\textbf{üè≠} #1,
    fonttitle=\bfseries,
    boxrule=0.8mm,
    arc=2mm
}

\newtcolorbox{sciencebox}[1]{
    colback=violet!5!white,
    colframe=violet!75!black,
    title=\textbf{üî¨} #1,
    fonttitle=\bfseries,
    boxrule=0.8mm,
    arc=2mm
}

% --- ESTILO DE C√ìDIGO ---
\lstdefinestyle{pythonstyle}{
    backgroundcolor=\color{codebg},
    commentstyle=\color{gray}\itshape,
    keywordstyle=\color{pandas}\bfseries,
    numberstyle=\tiny\color{gray},
    stringstyle=\color{accent},
    basicstyle=\ttfamily\footnotesize,
    breaklines=true,
    frame=l,
    rulecolor=\color{pandas},
    numbers=left,
    showstringspaces=false,
    literate=
        {√°}{{\'a}}1 {√©}{{\'e}}1 {√≠}{{\'i}}1 {√≥}{{\'o}}1 {√∫}{{\'u}}1 {√±}{{\~n}}1
        {‚ö†}{{\textcolor{orange}{\bfseries !}}}1
        {NaN}{{\textcolor{red}{\bfseries NaN}}}3
        {None}{{\textcolor{red}{\bfseries None}}}4
}

\lstset{style=pythonstyle}

% --- ENCABEZADO ---
\pagestyle{fancy}
\fancyhf{}
\lhead{\textbf{Ingenier√≠a de IA I}}
\rhead{Semana 03: Pandas para Agroindustria}
\rfoot{P√°gina \thepage}

\title{\textbf{Pandas para Procesamiento Industrial}\\
       \large Trazabilidad, Control de Calidad y An√°lisis de Producci√≥n\\
       Agroindustria Alimenticia 4.0}
\author{Curso de IA Aplicada al Agro\\
        Universidad del Valle}
\date{Enero 2026}

\begin{document}

\maketitle

\begin{abstract}
Este manual introduce Pandas desde la perspectiva de la ingenier√≠a de datos aplicada a la industria alimenticia. A diferencia del enfoque tradicional basado en an√°lisis exploratorio gen√©rico, aqu√≠ abordamos problemas reales de trazabilidad de lotes, control estad√≠stico de procesos (SPC), cumplimiento normativo (HACCP, FDA) y optimizaci√≥n de l√≠neas de producci√≥n. Los estudiantes aprender√°n a procesar datasets heterog√©neos (fechas, categor√≠as, mediciones num√©ricas) con eficiencia computacional y rigor cient√≠fico.
\end{abstract}

\tableofcontents
\newpage

\section*{Prefacio: Del Campo a la Mesa}

En la Semana 02 trabajaste con NumPy procesando matrices num√©ricas homog√©neas (humedad del suelo en 365 d√≠as √ó 100 zonas). Ese enfoque funciona para sensores agr√≠colas, pero \textbf{la agroindustria moderna genera datos m√°s complejos}:

\begin{itemize}
    \item \textbf{Trazabilidad}: Cada lote de caf√© procesado tiene ID (string), timestamp de entrada/salida, temperatura de tostado (float), operario responsable (categor√≠a), resultado QA (booleano).
    \item \textbf{Series temporales irregulares}: Sensores IoT env√≠an datos cada 30 segundos, pero fallan aleatoriamente.
    \item \textbf{Relaciones entre tablas}: Para rastrear un recall de producto, debes cruzar 3 datasets: \texttt{lotes\_producidos}, \texttt{pruebas\_laboratorio}, \texttt{despachos\_clientes}.
\end{itemize}

NumPy no est√° dise√±ado para esto. \textbf{Pandas s√≠}.

\begin{industrybox}{Contexto Industrial}
Imagina una planta procesadora de alimentos que opera 24/7 en 3 turnos, con 5 l√≠neas de producci√≥n y 1200 lotes/mes. Cada lote genera:
\begin{itemize}
    \item 8 variables de proceso (temperatura, presi√≥n, pH, humedad, tiempo)
    \item 12 pruebas de laboratorio (microbiolog√≠a, f√≠sico-qu√≠micas)
    \item Metadatos de trazabilidad (proveedor, lote de materia prima, destino)
\end{itemize}

\textbf{Total}: 14,400 lotes/a√±o √ó 20 variables = 288,000 datos/a√±o.

\textit{No puedes analizar esto en Excel. Necesitas c√≥digo profesional.}
\end{industrybox}

\newpage

\section{Cap√≠tulo I: Fundamentos ‚Äî DataFrame como Base de Datos en Memoria}

\subsection{La Anatom√≠a de un DataFrame}

Un DataFrame es una \textbf{tabla en memoria RAM} con √≠ndice expl√≠cito y columnas etiquetadas. A diferencia de NumPy (donde accedes por posici√≥n), Pandas permite consultas tipo SQL.

\begin{center}
\begin{tikzpicture}[
    node distance=1.5cm,
    box/.style={rectangle, draw, minimum width=3cm, minimum height=1.2cm, align=center, rounded corners},
    arrow/.style={->, thick, >=stealth}
]
    % Componentes
    \node[box, fill=blue!10] (index) {\textbf{Index}\\ (Etiquetas de filas)};
    \node[box, fill=green!10, right=of index] (columns) {\textbf{Columns}\\ (Nombres de variables)};
    \node[box, fill=orange!10, below=of index] (values) {\textbf{Values}\\ (NumPy array 2D)};
    \node[box, fill=violet!10, below=of columns] (dtypes) {\textbf{Dtypes}\\ (Tipos por columna)};

    % Relaciones
    \draw[arrow] (index) -- (values) node[midway, left, font=\tiny] {Mapeo de filas};
    \draw[arrow] (columns) -- (values) node[midway, right, font=\tiny] {Mapeo de columnas};
    \draw[arrow] (columns) -- (dtypes) node[midway, right, font=\tiny] {Especifica tipos};
\end{tikzpicture}
\end{center}

\textbf{Diferencia clave con NumPy}:
\begin{itemize}
    \item NumPy: \texttt{array[0, 3]} ‚Üí Posici√≥n absoluta (fila 0, columna 3)
    \item Pandas: \texttt{df.loc["2026-01-01", "Temperatura"]} ‚Üí Etiqueta sem√°ntica
\end{itemize}

\subsection{Series vs DataFrame}

\begin{table}[h]
\centering
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Caracter√≠stica} & \textbf{Series} & \textbf{DataFrame} \\
\midrule
Dimensionalidad & 1D (columna √∫nica) & 2D (tabla) \\
Tipo de datos & Homog√©neo (un dtype) & Heterog√©neo (dtype por columna) \\
Index & S√≠ & S√≠ \\
Operaciones & Vectorizadas & Por columna/fila \\
Uso t√≠pico & Una medici√≥n & Dataset completo \\
\bottomrule
\end{tabular}
\caption{Comparaci√≥n Series-DataFrame}
\end{table}

\begin{lstlisting}[language=Python, caption={Crear Series y DataFrame desde c√≥digo}]
import pandas as pd
import numpy as np

# Series: Una columna de temperaturas
temps = pd.Series([72.5, 73.1, 72.8, 74.0],
                  index=['Lote_A', 'Lote_B', 'Lote_C', 'Lote_D'],
                  name='Temperatura_Pasteurizacion')

print(temps['Lote_B'])  # Acceso por etiqueta ‚Üí 73.1

# DataFrame: Tabla completa de un turno
data = {
    'id_lote': ['L001', 'L002', 'L003'],
    'temp_C': [72.5, 73.1, 71.9],
    'presion_bar': [2.8, 2.9, 2.7],
    'resultado_QA': ['Aprobado', 'Aprobado', 'Rechazado']
}

df = pd.DataFrame(data)
print(df.dtypes)
\end{lstlisting}

\subsection{Carga de Datos Industriales}

En la industria, los datos vienen de m√∫ltiples fuentes:

\begin{itemize}
    \item \textbf{SCADA} (sistemas de control): CSV/Excel con timestamps
    \item \textbf{LIMS} (laboratorio): Resultados en archivos Excel con hojas m√∫ltiples
    \item \textbf{ERP} (SAP/Oracle): Exportaciones CSV con separadores raros
    \item \textbf{Sensores IoT}: JSON desde APIs REST
\end{itemize}

\begin{lstlisting}[language=Python, caption={Carga robusta de datos industriales}]
import pandas as pd

# 1. CSV con problemas comunes
df_scada = pd.read_csv(
    'datos_scada.csv',
    sep=';',                      # Separador europeo
    decimal=',',                  # Decimales con coma
    encoding='latin1',            # Codificaci√≥n Windows
    parse_dates=['timestamp'],    # Convertir a datetime autom√°ticamente
    na_values=['error', 'offline', '-'],  # Valores nulos personalizados
    dtype={'id_lote': str}        # Forzar ID como texto (evita 001 ‚Üí 1)
)

# 2. Excel con m√∫ltiples hojas
df_lab = pd.read_excel(
    'resultados_laboratorio.xlsx',
    sheet_name='Microbiologia',   # Hoja espec√≠fica
    header=2,                      # La fila 3 tiene los t√≠tulos
    usecols='A:F'                  # Solo columnas A-F
)

# 3. JSON desde API de sensor IoT
import requests
response = requests.get('https://api.sensores.com/temperatura')
df_temp = pd.DataFrame(response.json()['data'])
\end{lstlisting}

\newpage

\section{Cap√≠tulo II: Indexaci√≥n y Selecci√≥n ‚Äî El Fundamento de Todo}

\subsection{Los 3 M√©todos de Acceso}

\begin{warningbox}{Error \#1 m√°s com√∫n en Pandas}
Confundir \texttt{.loc[]} (etiquetas) con \texttt{.iloc[]} (posiciones). Esto causa bugs silenciosos cuando el √≠ndice no es secuencial.
\end{warningbox}

\begin{table}[h]
\centering
\rowcolors{2}{gray!10}{white}
\begin{tabular}{@{}lp{5cm}p{6cm}@{}}
\toprule
\textbf{M√©todo} & \textbf{Qu√© usa} & \textbf{Ejemplo industrial} \\
\midrule
\texttt{.loc[]} & Etiquetas (labels) & \texttt{df.loc["2026-01-15", "pH"]} \\
\texttt{.iloc[]} & Posici√≥n (enteros) & \texttt{df.iloc[0, 3]} (primera fila, cuarta columna) \\
\texttt{df[]} & Columnas (principalmente) & \texttt{df["Temperatura"]} \\
\bottomrule
\end{tabular}
\caption{M√©todos de indexaci√≥n en Pandas}
\end{table}

\begin{lstlisting}[language=Python, caption={Ejemplos de indexaci√≥n}]
import pandas as pd

# Dataset simulado: Control de calidad de leche
data = {
    'id_lote': ['L001', 'L002', 'L003', 'L004'],
    'fecha': ['2026-01-10', '2026-01-10', '2026-01-11', '2026-01-11'],
    'temp_pasteurizacion': [72.5, 73.0, 71.8, 74.2],
    'ph': [6.7, 6.6, 6.5, 6.9],
    'resultado': ['Aprobado', 'Aprobado', 'Rechazado', 'Aprobado']
}

df = pd.DataFrame(data)

# 1. SELECCI√ìN DE COLUMNAS
temps = df['temp_pasteurizacion']  # Retorna Series
subset = df[['id_lote', 'ph']]     # Retorna DataFrame (nota el [[ ]])

# 2. SELECCI√ìN POR ETIQUETA (.loc)
# Sintaxis: df.loc[filas, columnas]
primera_fila = df.loc[0]                    # Primera fila completa
ph_L002 = df.loc[1, 'ph']                   # Celda espec√≠fica: 6.6
rango = df.loc[0:2, 'temp_pasteurizacion']  # Filas 0-2, una columna

# 3. SELECCI√ìN POR POSICI√ìN (.iloc)
primera_celda = df.iloc[0, 0]     # 'L001'
subcuadro = df.iloc[0:2, 1:3]     # 2 filas √ó 2 columnas
\end{lstlisting}

\subsection{Filtrado Booleano (M√°scaras)}

El poder real de Pandas est√° en las \textbf{consultas vectorizadas}. No uses bucles \texttt{for} ‚Äî usa m√°scaras booleanas.

\begin{lstlisting}[language=Python, caption={Filtrado avanzado para control de calidad}]
import pandas as pd

# Cargar datos de producci√≥n
df = pd.read_csv('produccion_cafe_enero.csv')

# 1. CONSULTA SIMPLE: Lotes rechazados
rechazados = df[df['resultado'] == 'Rechazado']

# 2. CONSULTAS COMPUESTAS: Temperatura fuera de spec Y presi√≥n baja
# Rango de pasteurizaci√≥n: 72-76¬∞C, Presi√≥n m√≠nima: 2.5 bar
problemas_criticos = df[
    ((df['temp_C'] < 72) | (df['temp_C'] > 76)) &
    (df['presion_bar'] < 2.5)
]

# 3. FILTRO POR LISTA (isin): Solo l√≠neas L1 y L3
lineas_foco = df[df['linea'].isin(['L1', 'L3'])]

# 4. FILTRO POR STRING (contiene): Lotes de turno nocturno
nocturnos = df[df['id_lote'].str.contains('NOCHE')]

# 5. QUERY (sintaxis SQL-like)
# Nota: Solo funciona si nombres de columnas no tienen espacios
criticos = df.query('temp_C > 76 and resultado == "Rechazado"')
\end{lstlisting}

\begin{sciencebox}{Complejidad Computacional de M√°scaras}
Una m√°scara booleana \texttt{df['temp'] > 72} tiene complejidad \( O(n) \) donde \( n \) es el n√∫mero de filas. Internamente:
\begin{enumerate}
    \item Pandas delega la comparaci√≥n a NumPy (c√≥digo C optimizado)
    \item Se crea un array booleano en memoria del mismo tama√±o que la columna
    \item El filtrado \texttt{df[mask]} usa fancy indexing de NumPy
\end{enumerate}

Para un DataFrame de 1M filas, esto toma $\sim$10ms. Un bucle \texttt{for} equivalente tomar√≠a $\sim$2 segundos (200x m√°s lento).
\end{sciencebox}

\newpage

\section{Cap√≠tulo III: Limpieza de Datos ‚Äî Fail Fast en Producci√≥n}

\subsection{El Problema de los Tipos Incorrectos}

\begin{warningbox}{Tipo \texttt{object} = Peligro}
Si una columna num√©rica aparece como \texttt{dtype: object}, significa que Pandas la ley√≥ como texto. No podr√°s hacer operaciones matem√°ticas hasta convertirla.
\end{warningbox}

\textbf{Causas comunes}:
\begin{itemize}
    \item Un solo valor con texto ("Error", "N/A", "-") contamina toda la columna
    \item Formato de n√∫mero europeo: "3,14" en lugar de "3.14"
    \item Espacios en blanco: " 25.5 " no se convierte autom√°ticamente
\end{itemize}

\begin{lstlisting}[language=Python, caption={Diagn√≥stico y correcci√≥n de tipos}]
import pandas as pd

df = pd.read_csv('sensores_planta.csv')

# 1. DIAGN√ìSTICO
print(df.dtypes)
print(df.info())  # Muestra tipos y valores no-nulos

# Ejemplo de salida problem√°tica:
# temperatura    object  ‚Üê ‚ö† Deber√≠a ser float64
# presion        object  ‚Üê ‚ö† Deber√≠a ser float64

# 2. INSPECCI√ìN MANUAL
print(df['temperatura'].unique())  # Ver valores √∫nicos
# Output: ['25.5', '26.1', 'Error', '24.8', ...]  ‚Üê "Error" causa el problema

# 3. CONVERSI√ìN FORZADA (errores ‚Üí NaN)
df['temperatura'] = pd.to_numeric(df['temperatura'], errors='coerce')
df['presion'] = pd.to_numeric(df['presion'], errors='coerce')

# 4. VERIFICACI√ìN
print(df.dtypes)
# temperatura    float64  ‚Üê ‚úì Corregido
# presion        float64  ‚Üê ‚úì Corregido

print(df['temperatura'].isna().sum())  # Contar cu√°ntos NaN se generaron
\end{lstlisting}

\subsection{Tratamiento de Valores Faltantes}

En la industria alimenticia, \textbf{un dato faltante puede significar un fallo cr√≠tico}. No siempre es correcto rellenar con el promedio.

\begin{table}[h]
\centering
\begin{tabular}{@{}lp{6cm}p{5cm}@{}}
\toprule
\textbf{M√©todo} & \textbf{Cu√°ndo usarlo} & \textbf{Riesgo} \\
\midrule
\texttt{fillna(0)} & Contadores (eventos) & 0 puede ser v√°lido en agro \\
\texttt{ffill()} & Series temporales (sensores) & Oculta fallos prolongados \\
\texttt{interpolate()} & Datos continuos (temperatura) & Inventa datos inexistentes \\
\texttt{dropna()} & QA cr√≠tico & Pierdes informaci√≥n \\
\bottomrule
\end{tabular}
\caption{Estrategias de imputaci√≥n de datos faltantes}
\end{table}

\begin{lstlisting}[language=Python, caption={Imputaci√≥n contextual para sensores}]
import pandas as pd

df = pd.read_csv('temperatura_camara_fria.csv', parse_dates=['timestamp'])
df = df.set_index('timestamp')

# CASO 1: Interpolaci√≥n limitada (m√°ximo 2 valores consecutivos)
# Si faltan >2 valores, algo fall√≥ y no deber√≠amos inventar datos
df['temp'] = df['temp'].interpolate(method='time', limit=2)

# CASO 2: Forward fill con l√≠mite temporal
# Rellenar con el √∫ltimo valor conocido, pero solo por 10 minutos
df['humedad'] = df['humedad'].fillna(method='ffill', limit=20)  # 20 registros = 10 min

# CASO 3: Marcar como fallo en lugar de imputar
df['sensor_falla'] = df['temp'].isna()  # Columna booleana de alertas

# CASO 4: Eliminar filas con datos cr√≠ticos faltantes
df_limpio = df.dropna(subset=['ph', 'acidez'])  # Solo si faltan variables cr√≠ticas
\end{lstlisting}

\subsection{Detecci√≥n de Outliers}

\begin{lstlisting}[language=Python, caption={Detecci√≥n estad√≠stica de anomal√≠as}]
import pandas as pd
import numpy as np

df = pd.read_csv('temperatura_pasteurizacion.csv')

# M√âTODO 1: Rango intercuart√≠lico (IQR) ‚Äî Robusto a valores extremos
Q1 = df['temp'].quantile(0.25)
Q3 = df['temp'].quantile(0.75)
IQR = Q3 - Q1

limite_inferior = Q1 - 1.5 * IQR
limite_superior = Q3 + 1.5 * IQR

outliers = df[(df['temp'] < limite_inferior) | (df['temp'] > limite_superior)]
print(f"Detectados {len(outliers)} outliers")

# M√âTODO 2: Z-score (asume distribuci√≥n normal)
mean = df['temp'].mean()
std = df['temp'].std()
df['z_score'] = (df['temp'] - mean) / std

# Outliers: |z| > 3 (regla de 3 sigmas)
outliers_zscore = df[np.abs(df['z_score']) > 3]

# M√âTODO 3: L√≠mites f√≠sicos (conocimiento del dominio)
# La temperatura de pasteurizaci√≥n NUNCA puede ser > 100¬∞C
errores_sensor = df[df['temp'] > 100]
df.loc[df['temp'] > 100, 'temp'] = np.nan  # Marcar como faltante
\end{lstlisting}

\newpage

\section{Cap√≠tulo IV: GroupBy ‚Äî El Motor de Agregaci√≥n}

\subsection{El Paradigma Split-Apply-Combine}

\texttt{.groupby()} es la operaci√≥n m√°s importante en Pandas. Implementa el patr√≥n \textit{split-apply-combine}:

\begin{center}
\begin{tikzpicture}[
    node distance=2cm,
    box/.style={rectangle, draw, minimum width=2.5cm, minimum height=1.2cm, align=center, rounded corners, thick},
    arrow/.style={->, ultra thick, >=stealth}
]
    \node[box, fill=blue!20] (original) {DataFrame\\Original};
    \node[box, fill=green!20, below=of original] (split) {SPLIT\\(Dividir por grupos)};
    \node[box, fill=orange!20, below=of split] (apply) {APPLY\\(Aplicar funci√≥n)};
    \node[box, fill=violet!20, below=of apply] (combine) {COMBINE\\(Combinar resultados)};

    \draw[arrow] (original) -- (split);
    \draw[arrow] (split) -- (apply);
    \draw[arrow] (apply) -- (combine);
\end{tikzpicture}
\end{center}

\begin{lstlisting}[language=Python, caption={An√°lisis de productividad por l√≠nea}]
import pandas as pd

# Dataset: 2000 lotes de caf√© procesados en enero
df = pd.read_csv('produccion_cafe_enero.csv', parse_dates=['timestamp_inicio', 'timestamp_fin'])

# Calcular duraci√≥n de cada lote
df['duracion_min'] = (df['timestamp_fin'] - df['timestamp_inicio']).dt.total_seconds() / 60

# AGREGACI√ìN 1: Productividad por l√≠nea
productividad = df.groupby('linea').agg({
    'kg_procesados': 'sum',         # Total de kilos
    'duracion_min': 'mean',          # Duraci√≥n promedio
    'id_lote': 'count'               # Cantidad de lotes
})

print(productividad)
# Output:
#       kg_procesados  duracion_min  id_lote
# linea
# L1            45000          87.2      650
# L2            38000          92.1      520
# L3            42000          89.5      600

# AGREGACI√ìN 2: Rechazos por turno
rechazos = df.groupby(['turno', 'resultado']).size().unstack(fill_value=0)
print(rechazos)

# AGREGACI√ìN 3: M√∫ltiples estad√≠sticas
stats = df.groupby('linea')['duracion_min'].agg(['mean', 'std', 'min', 'max'])
\end{lstlisting}

\subsection{GroupBy con Transformaciones}

A veces no quieres reducir el DataFrame, sino \textbf{agregar columnas calculadas por grupo}.

\begin{lstlisting}[language=Python, caption={Normalizaci√≥n por grupo}]
import pandas as pd

df = pd.read_csv('lotes_produccion.csv')

# CASO 1: Calcular % de productividad de cada lote respecto a su l√≠nea
df['kg_promedio_linea'] = df.groupby('linea')['kg_procesados'].transform('mean')
df['performance_relativo'] = (df['kg_procesados'] / df['kg_promedio_linea']) * 100

# CASO 2: Ranking dentro de cada turno
df['ranking_turno'] = df.groupby('turno')['kg_procesados'].rank(ascending=False)

# CASO 3: Detectar lotes at√≠picos (> 2 std de su grupo)
df['media_linea'] = df.groupby('linea')['duracion_min'].transform('mean')
df['std_linea'] = df.groupby('linea')['duracion_min'].transform('std')
df['es_atipico'] = (df['duracion_min'] - df['media_linea']).abs() > (2 * df['std_linea'])
\end{lstlisting}

\begin{sciencebox}{Complejidad de GroupBy}
Internamente, \texttt{.groupby()} usa un algoritmo de hashing para agrupar filas:
\begin{enumerate}
    \item Calcula hash de cada valor en la columna de agrupaci√≥n: \( O(n) \)
    \item Ordena los √≠ndices por hash: \( O(n \log n) \)
    \item Aplica funci√≥n a cada grupo: \( O(n) \)
\end{enumerate}

Complejidad total: \( O(n \log n) \). Para 1M filas, esto toma $\sim$100ms en un CPU moderno.

\textbf{Comparaci√≥n}: Un bucle manual con diccionarios tomar√≠a $\sim$5 segundos (50x m√°s lento).
\end{sciencebox}

\newpage

\section{Cap√≠tulo V: Series Temporales ‚Äî El Coraz√≥n de la Industria}

\subsection{Datetime como Index}

En la industria, \textbf{el tiempo es el √≠ndice natural} de los datos. Convertir el DataFrame a √≠ndice temporal desbloquea operaciones avanzadas.

\begin{lstlisting}[language=Python, caption={Configurar √≠ndice temporal}]
import pandas as pd

# Cargar datos de sensor con timestamps
df = pd.read_csv('temperatura_camara.csv')

# PASO 1: Convertir columna a datetime
df['timestamp'] = pd.to_datetime(df['timestamp'])

# PASO 2: Establecer como √≠ndice
df = df.set_index('timestamp')

# PASO 3: Ordenar por tiempo (¬°importante!)
df = df.sort_index()

# Ahora puedes hacer selecci√≥n por rangos de fecha:
enero = df['2026-01-01':'2026-01-31']
primera_semana = df['2026-01-01':'2026-01-07']
\end{lstlisting}

\subsection{Resampling ‚Äî Cambiar la Frecuencia}

\begin{conceptbox}{Resampling vs Rolling}
\begin{itemize}
    \item \textbf{Resample}: Cambia la frecuencia temporal. Ejemplo: datos cada 30 seg ‚Üí promedio diario.
    \item \textbf{Rolling}: Ventana deslizante. Mantiene la frecuencia original pero suaviza con promedios m√≥viles.
\end{itemize}
\end{conceptbox}

\begin{lstlisting}[language=Python, caption={Resampling para reportes diarios}]
import pandas as pd

# Datos de temperatura cada 30 segundos
df = pd.read_csv('temp_pasteurizacion.csv', parse_dates=['timestamp'], index_col='timestamp')

# RESAMPLE 1: Promedio diario
temp_diaria = df['temperatura'].resample('D').mean()

# RESAMPLE 2: M√°ximo por hora
temp_horaria_max = df['temperatura'].resample('H').max()

# RESAMPLE 3: M√∫ltiples agregaciones
stats_diarias = df.resample('D').agg({
    'temperatura': ['mean', 'min', 'max', 'std'],
    'presion': 'mean'
})

# RESAMPLE 4: Contar eventos por turno (8 horas)
eventos_turno = df.resample('8H').count()
\end{lstlisting}

\subsection{Rolling Windows ‚Äî Suavizar Ruido}

\begin{lstlisting}[language=Python, caption={Ventanas m√≥viles para control de procesos}]
import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv('temperatura_real_time.csv', parse_dates=['timestamp'], index_col='timestamp')

# Media m√≥vil de 10 minutos (window=20 si los datos son cada 30 seg)
df['temp_suavizada'] = df['temperatura'].rolling(window=20).mean()

# Desviaci√≥n est√°ndar m√≥vil (detectar variabilidad)
df['temp_std_movil'] = df['temperatura'].rolling(window=20).std()

# Detectar derivas: si la std m√≥vil supera 2¬∞C, el proceso est√° inestable
df['proceso_inestable'] = df['temp_std_movil'] > 2.0

# Visualizaci√≥n
plt.figure(figsize=(12, 6))
plt.plot(df.index, df['temperatura'], alpha=0.3, label='Datos crudos')
plt.plot(df.index, df['temp_suavizada'], linewidth=2, label='Media m√≥vil 10 min')
plt.legend()
plt.title('Control de Temperatura - Pasteurizaci√≥n')
plt.savefig('control_temperatura.png', dpi=150)
\end{lstlisting}

\newpage

\section{Cap√≠tulo VI: Merge y Trazabilidad ‚Äî Conectar las Piezas}

\subsection{El Problema de la Trazabilidad}

En agroindustria alimenticia, la trazabilidad es \textbf{un requisito legal} (HACCP, ISO 22000, FDA). Debes poder responder:

\begin{itemize}
    \item ¬øQu√© clientes recibieron lotes de un proveedor contaminado?
    \item ¬øQu√© lotes fueron procesados por un operario espec√≠fico en una fecha?
    \item ¬øQu√© materia prima se us√≥ en un lote con defecto?
\end{itemize}

Esto requiere \textbf{cruzar m√∫ltiples tablas}.

\subsection{Tipos de Merge}

\begin{table}[h]
\centering
\begin{tabular}{@{}lp{8cm}@{}}
\toprule
\textbf{Tipo} & \textbf{Comportamiento} \\
\midrule
\texttt{inner} & Solo filas con match en ambas tablas (intersecci√≥n) \\
\texttt{left} & Todas las filas de la tabla izquierda + matches de la derecha \\
\texttt{right} & Todas las filas de la tabla derecha + matches de la izquierda \\
\texttt{outer} & Todas las filas de ambas tablas (uni√≥n) \\
\bottomrule
\end{tabular}
\caption{Tipos de merge en Pandas}
\end{table}

\begin{lstlisting}[language=Python, caption={Caso HACCP: Rastreo de lote contaminado}]
import pandas as pd

# PASO 1: Cargar las 3 tablas
lotes = pd.read_csv('lotes_producidos.csv')
# Columnas: id_lote, fecha_produccion, kg, linea

pruebas = pd.read_csv('pruebas_laboratorio.csv')
# Columnas: id_lote, ph, acidez, resultado

despachos = pd.read_csv('despachos.csv')
# Columnas: id_lote, cliente, fecha_envio, destino

# PASO 2: Primera uni√≥n (lotes + pruebas)
lotes_con_qa = pd.merge(lotes, pruebas, on='id_lote', how='left')

# PASO 3: Segunda uni√≥n (agregar despachos)
trazabilidad_completa = pd.merge(lotes_con_qa, despachos, on='id_lote', how='left')

# PASO 4: Identificar lotes problem√°ticos (pH < 4.3)
lotes_problematicos = trazabilidad_completa[trazabilidad_completa['ph'] < 4.3]

# PASO 5: Listar clientes afectados
clientes_afectados = lotes_problematicos[['id_lote', 'cliente', 'destino', 'fecha_envio']]
print(clientes_afectados)

# PASO 6: Exportar para reporte de recall
clientes_afectados.to_csv('recall_lista_clientes.csv', index=False)
\end{lstlisting}

\begin{warningbox}{Error Com√∫n: Claves con tipos diferentes}
Si \texttt{lotes['id\_lote']} es string y \texttt{pruebas['id\_lote']} es int, el merge fallar√° silenciosamente (0 matches).

\textbf{Soluci√≥n}: Siempre verificar tipos antes de merge:
\begin{lstlisting}[language=Python]
print(lotes['id_lote'].dtype)
print(pruebas['id_lote'].dtype)

# Si son diferentes, convertir:
lotes['id_lote'] = lotes['id_lote'].astype(str)
pruebas['id_lote'] = pruebas['id_lote'].astype(str)
\end{lstlisting}
\end{warningbox}

\newpage

\section{Cap√≠tulo VII: Ingenier√≠a de Caracter√≠sticas}

\subsection{Creaci√≥n de Columnas Derivadas}

\begin{lstlisting}[language=Python, caption={Variables calculadas para an√°lisis}]
import pandas as pd

df = pd.read_csv('produccion_diaria.csv', parse_dates=['fecha'])

# 1. Duraci√≥n de proceso (timedelta a minutos)
df['duracion_min'] = (df['hora_fin'] - df['hora_inicio']).dt.total_seconds() / 60

# 2. Rendimiento (kg/hora)
df['rendimiento'] = df['kg_producidos'] / (df['duracion_min'] / 60)

# 3. Categorizaci√≥n de turnos
def clasificar_turno(hora):
    if 6 <= hora < 14:
        return 'Ma√±ana'
    elif 14 <= hora < 22:
        return 'Tarde'
    else:
        return 'Noche'

df['turno'] = df['hora_inicio'].dt.hour.apply(clasificar_turno)

# 4. D√≠a de la semana (√∫til para detectar patrones)
df['dia_semana'] = df['fecha'].dt.day_name()

# 5. Semana del a√±o (agrupaci√≥n temporal)
df['semana'] = df['fecha'].dt.isocalendar().week
\end{lstlisting}

\subsection{Discretizaci√≥n (Binning)}

\begin{lstlisting}[language=Python, caption={Clasificar variables continuas en categor√≠as}]
import pandas as pd

df = pd.read_csv('analisis_ph.csv')

# Clasificar pH en categor√≠as
bins = [0, 6.5, 7.0, 14]
labels = ['√Åcido', 'Neutro', 'Alcalino']
df['categoria_ph'] = pd.cut(df['ph'], bins=bins, labels=labels)

# Clasificar temperatura de pasteurizaci√≥n en zonas
bins_temp = [0, 71, 74, 77, 100]
labels_temp = ['Bajo Spec', '√ìptimo Bajo', '√ìptimo Alto', 'Sobre Spec']
df['zona_temp'] = pd.cut(df['temp'], bins=bins_temp, labels=labels_temp)
\end{lstlisting}

\newpage

\section{Cap√≠tulo VIII: √âtica y Calidad de Datos}

\begin{ethicsbox}{Responsabilidad en la Limpieza de Datos}
Cada decisi√≥n de limpieza altera la realidad registrada. En la industria alimenticia, esto tiene implicaciones legales y de salud p√∫blica.

\textbf{Principios √©ticos}:
\begin{enumerate}
    \item \textbf{Trazabilidad}: Guardar dataset original sin modificar (\texttt{raw/})
    \item \textbf{Documentaci√≥n}: Registrar cada transformaci√≥n en un log
    \item \textbf{Transparencia}: Reportar cu√°ntas filas se eliminaron y por qu√©
    \item \textbf{Sesgo de imputaci√≥n}: No ocultar fallos sistem√°ticos rellenando con promedios
\end{enumerate}
\end{ethicsbox}

\subsection{Pipeline de Limpieza Documentado}

\begin{lstlisting}[language=Python, caption={Pipeline con logging}]
import pandas as pd
import logging

# Configurar logging
logging.basicConfig(filename='limpieza.log', level=logging.INFO)

def limpiar_dataset(path_entrada, path_salida):
    # Cargar datos crudos
    df = pd.read_csv(path_entrada)
    filas_originales = len(df)
    logging.info(f"Dataset cargado: {filas_originales} filas")

    # 1. Eliminar duplicados
    df = df.drop_duplicates()
    duplicados = filas_originales - len(df)
    logging.info(f"Duplicados eliminados: {duplicados}")

    # 2. Convertir tipos
    df['temperatura'] = pd.to_numeric(df['temperatura'], errors='coerce')
    nulos_generados = df['temperatura'].isna().sum()
    logging.info(f"Valores no num√©ricos convertidos a NaN: {nulos_generados}")

    # 3. Eliminar outliers
    Q1 = df['temperatura'].quantile(0.25)
    Q3 = df['temperatura'].quantile(0.75)
    IQR = Q3 - Q1
    df_limpio = df[
        (df['temperatura'] >= Q1 - 1.5*IQR) &
        (df['temperatura'] <= Q3 + 1.5*IQR)
    ]
    outliers = len(df) - len(df_limpio)
    logging.info(f"Outliers eliminados: {outliers}")

    # Guardar dataset limpio
    df_limpio.to_csv(path_salida, index=False)
    logging.info(f"Dataset final: {len(df_limpio)} filas guardadas en {path_salida}")

    return df_limpio

# Ejecutar
df_limpio = limpiar_dataset('data/raw/sensores.csv', 'data/processed/sensores_clean.csv')
\end{lstlisting}

\newpage

\section{Cap√≠tulo IX: Talleres Pr√°cticos}

\subsection{Taller 1: An√°lisis de L√≠nea de Producci√≥n}

\begin{industrybox}{Caso: Planta de Procesamiento de Caf√©}
Tienes 2000 lotes procesados en enero en 3 l√≠neas (L1, L2, L3). Debes analizar productividad, identificar cuellos de botella y generar reporte ejecutivo.
\end{industrybox}

\textbf{Dataset}: \texttt{produccion\_cafe\_enero.csv}

\textbf{Tareas}:
\begin{enumerate}
    \item Calcular duraci√≥n promedio por l√≠nea
    \item Identificar el turno m√°s lento
    \item Detectar lotes con duraci√≥n > 2 desviaciones est√°ndar
    \item Generar tabla resumen con productividad (kg/hora)
\end{enumerate}

\subsection{Taller 2: Control de Calidad Temporal}

\begin{industrybox}{Caso: Pasteurizaci√≥n de Leche}
Sensor registra temperatura cada 30 segundos durante una semana. Debes detectar derivas, generar alertas y producir gr√°ficos de control.
\end{industrybox}

\textbf{Dataset}: \texttt{temperatura\_pasteurizacion\_semana.csv}

\textbf{Tareas}:
\begin{enumerate}
    \item Resamplear a promedios de 10 minutos
    \item Calcular desviaci√≥n est√°ndar m√≥vil (ventana 20 lecturas)
    \item Detectar periodos con temperatura fuera de [72-76¬∞C] por >5 minutos
    \item Visualizar con matplotlib
\end{enumerate}

\subsection{Taller 3: Trazabilidad y Recall}

\begin{industrybox}{Caso HACCP: Lote Contaminado}
Se detect√≥ contaminaci√≥n microbiol√≥gica en el lote L20260115\_042. Debes rastrear qu√© clientes lo recibieron y generar lista para recall.
\end{industrybox}

\textbf{Datasets}:
\begin{itemize}
    \item \texttt{lotes\_producidos.csv}
    \item \texttt{pruebas\_microbiologia.csv}
    \item \texttt{despachos\_clientes.csv}
\end{itemize}

\textbf{Tareas}:
\begin{enumerate}
    \item Merge de las 3 tablas por \texttt{id\_lote}
    \item Filtrar lotes con resultado "Contaminado"
    \item Generar CSV con: cliente, direcci√≥n, fecha\_env√≠o, kg\_afectados
    \item Crear reporte LaTeX con tabla de afectados
\end{enumerate}
\newpage
\section{Cap√≠tulo X: Visualizaci√≥n Profesional con Matplotlib}

\subsection{Gr√°ficos de Control Estad√≠stico (SPC)}

Los gr√°ficos SPC son fundamentales en industria alimenticia para detectar derivas de proceso.

\begin{lstlisting}[language=Python, caption={Gr√°fico de control}]
import matplotlib.pyplot as plt
import pandas as pd

df = pd.read_csv('ph_lotes.csv')
media = df['ph'].mean()
std = df['ph'].std()
UCL = media + 3*std
LCL = media - 3*std

fig, ax = plt.subplots(figsize=(14, 6))
ax.scatter(df.index, df['ph'], alpha=0.7)
ax.axhline(y=media, color='green', linewidth=2, label='Media')
ax.axhline(y=UCL, color='red', linestyle='--', label='UCL')
ax.axhline(y=LCL, color='red', linestyle='--', label='LCL')
ax.legend()
plt.savefig('spc.png', dpi=300)
\end{lstlisting}

\newpage
\section{Cap√≠tulo XI: Estad√≠stica con SciPy}

\subsection{Pruebas de Hip√≥tesis}

\begin{lstlisting}[language=Python, caption={t-test entre turnos}]
from scipy import stats
import pandas as pd

df = pd.read_csv('defectos.csv')
diurno = df[df['turno'] == 'Diurno']['defectos']
nocturno = df[df['turno'] == 'Nocturno']['defectos']

t_stat, p_value = stats.ttest_ind(diurno, nocturno)

if p_value < 0.05:
    print("Diferencia significativa entre turnos")
\end{lstlisting}

\newpage
\section{Cap√≠tulo XII: SQL para Ciencia de Datos}

\subsection{Conexi√≥n y Queries}

\begin{lstlisting}[language=Python, caption={Pandas + SQL}]
import pandas as pd
from sqlalchemy import create_engine

engine = create_engine('postgresql://user:pass@localhost/planta')

df = pd.read_sql_query(
    "SELECT linea, AVG(kg) FROM lotes GROUP BY linea",
    engine
)
\end{lstlisting}

\section*{Referencias y Recursos}

\subsection*{Bibliograf√≠a Cient√≠fica}

\begin{enumerate}
    \item McKinney, W. (2017). \textit{Python for Data Analysis}. 2nd Edition. O'Reilly Media.
    \item VanderPlas, J. (2016). \textit{Python Data Science Handbook}. O'Reilly Media.
    \item Pandas Development Team (2024). \textit{Pandas Documentation}. \url{https://pandas.pydata.org/docs/}
\end{enumerate}

\subsection*{Est√°ndares Industriales}

\begin{itemize}
    \item ISO 22000:2018 ‚Äî Food Safety Management Systems
    \item FDA 21 CFR Part 11 ‚Äî Electronic Records and Signatures
    \item Codex Alimentarius ‚Äî HACCP Principles
\end{itemize}

\subsection*{Datasets de Pr√°ctica}

\begin{itemize}
    \item Kaggle: Food Safety Inspections
    \item UCI Machine Learning Repository: Wine Quality Dataset
    \item Open Food Facts: Global food products database
\end{itemize}

\end{document}
